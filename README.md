<<<<<<< HEAD
# 3. Infraestructura de Computaci칩n

Se ha desplegado un cl칰ster de **Hadoop y Spark** mediante contenedores **Docker**, cumpliendo con los requisitos de tolerancia a fallos y ejecuci칩n distribuida.  
El entorno incluye los siguientes nodos:

- **NameNode:** gestiona el espacio de nombres de HDFS.
- **DataNode:** almacena bloques de datos replicados.
- **Spark Master y Worker:** ejecutan tareas de an치lisis distribuido.
- **Cliente:** nodo desde el cual se env칤an trabajos Spark.

El cl칰ster permite ejecutar trabajos Spark correctamente y consultar las interfaces web:

- **NameNode:** http://localhost:9870  
- **Spark Master:** http://localhost:8080  

---

## 3.1 Uso de herramientas adicionales (5%)

Como herramienta transversal del **Tema 6**, se ha integrado **Dask**, un framework de procesamiento paralelo que permite ejecutar operaciones distribuidas sobre grandes vol칰menes de datos.  
Se han desplegado dos contenedores adicionales (`dask-scheduler` y `dask-worker`) y se ha creado un script `dask_analysis.py` que ejecuta un an치lisis del dataset de Netflix en paralelo.

**Dashboard Dask:** http://localhost:8787  

| Herramienta | Descripci칩n | Ventajas |
|--------------|--------------|-----------|
| **Spark** | Procesamiento distribuido completo (batch y SQL) | Escalable, robusto |
| **Dask** | Procesamiento paralelo en Python (API tipo Pandas) | Ligero, r치pido, simple |

El uso de Dask demuestra el empleo de herramientas transversales vistas en clase, aplicando los conceptos de *procesamiento paralelo, lazy evaluation* y *cluster computing*.
=======
#Proyecto ATBD Netflix

## 游닇 Descripci칩n del Proyecto

Este proyecto tiene como objetivo realizar un **An치lisis de T칤tulos de Netflix** utilizando herramientas de Big Data, espec칤ficamente **Apache Spark** sobre un entorno distribuido de **Hadoop** (HDFS).

El entorno se orquesta completamente mediante **Docker Compose**, lo que facilita la configuraci칩n y el despliegue de los servicios necesarios.

---

## Puesta en Marcha



---

## Estructura del Directorio

| Ruta | Descripci칩n |
| :--- | :--- |
| `docker/` | Contiene los **archivos de configuraci칩n** y **Dockerfiles** para construir las im치genes base de Hadoop y Spark. |
| `docker/Dockerfile` | Definici칩n de la imagen base. |
| `docker/hadoop/` | Archivos de configuraci칩n espec칤ficos de **Hadoop**. |
| `docker/spark/` | Archivos de configuraci칩n espec칤ficos de **Spark**. |
| `docker-compose.yml` | Archivo maestro para **definir y orquestar** los 5 contenedores del cl칰ster. |
| `scripts/` | Contiene **scripts de utilidad** para la inicializaci칩n y ejecuci칩n. |
| `scripts/init-hdfs.sh` | Script para **formatear HDFS** y crear directorios de usuario. |
| `scripts/submit.sh` | Script para **ejecutar el trabajo Spark** (`netflix_analysis.py`). |
| `code/` | Contiene el c칩digo fuente. |
| `code/netflix_analysis.py` | C칩digo **PySpark** para las anal칤ticas. |
| `data/` | Directorio para alojar los datasets de entrada. |
| `data/netflix_titles_nov_2019.csv` | El **dataset de Netflix** utilizado para el an치lisis. |

---

## Tecnolog칤as Utilizadas

* **Docker**
* **Docker Compose**
* **Apache Hadoop** (HDFS)
* **Apache Spark**
* **PySpark** (Python)
>>>>>>> d601ace76300a0403cd91557adb0997a7da2546f
