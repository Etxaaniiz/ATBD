from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("NetflixAnalysis").getOrCreate()

# Leer el CSV desde la carpeta local compartida (docker-compose monta ./data en /data)
df = spark.read.option("header", "true").csv("/data/netflix_titles_nov_2019.csv")

print("ğŸ“Š Estructura del dataset:")
df.printSchema()

# Mostrar las primeras filas
df.show(5)

# Contar el nÃºmero de tÃ­tulos por paÃ­s
print("\nğŸŒ Top 10 paÃ­ses con mÃ¡s tÃ­tulos:")
df.groupBy("country").count().orderBy("count", ascending=False).show(10)

# Contar pelÃ­culas vs series
print("\nğŸ¥ DistribuciÃ³n de tipo:")
df.groupBy("type").count().show()

spark.stop()