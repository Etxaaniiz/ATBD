from pyspark.sql import SparkSession
from pyspark.sql.functions import col, year, count, split, explode, avg, length, size, when
from pyspark.sql.functions import col, max as spark_max

# Crear sesi√≥n de Spark
spark = SparkSession.builder.appName("NetflixAnalysis").getOrCreate()

# Leer el CSV desde la carpeta compartida en el cl√∫ster
df = spark.read.option("header", "true").csv("/data/netflix_titles_nov_2019.csv")

print("üìä Estructura del dataset:")
df.printSchema()
df.show(5)

# ----------------------------------------------------------------------
# üîπ PUNTO 3 - Verificaci√≥n del cl√∫ster y an√°lisis b√°sico
# ----------------------------------------------------------------------

# Contar el n√∫mero de t√≠tulos por pa√≠s
print("\nüåç Top 10 pa√≠ses con m√°s t√≠tulos:")
df.groupBy("country").count().orderBy("count", ascending=False).show(10)

# Contar pel√≠culas vs series
print("\nüé• Distribuci√≥n de tipo de contenido:")
df.groupBy("type").count().show()

# ----------------------------------------------------------------------
# üîπ PUNTO 4 - An√°lisis de datos (10 preguntas anal√≠ticas)
# ----------------------------------------------------------------------

# Limpieza de datos: eliminar filas nulas en campos clave
df = df.dropna(subset=["title", "type", "release_year"])

print("\n‚úÖ Dataset limpio para an√°lisis")

# 1Ô∏è‚É£ Evoluci√≥n del n√∫mero de t√≠tulos por a√±o y tipo
print("\n1Ô∏è‚É£ ¬øC√≥mo ha evolucionado el n√∫mero de t√≠tulos a√±adidos a Netflix por a√±o y tipo?")
df.groupBy("release_year", "type") \
  .count() \
  .orderBy("release_year") \
  .show(20)

# 2Ô∏è‚É£ Pa√≠ses que producen m√°s contenido y evoluci√≥n temporal
print("\n2Ô∏è‚É£ ¬øQu√© pa√≠ses producen m√°s contenido y c√≥mo ha cambiado con el tiempo?")
df.groupBy("country", "release_year") \
  .count() \
  .orderBy(col("count").desc()) \
  .show(20)

# 3Ô∏è‚É£ G√©neros m√°s frecuentes en pel√≠culas y series
print("\n3Ô∏è‚É£ ¬øCu√°les son los g√©neros m√°s frecuentes por tipo?")
df_genres = df.withColumn("genre", explode(split(col("listed_in"), ", ")))
df_genres.groupBy("type", "genre").count().orderBy(col("count").desc()).show(20)

# 4Ô∏è‚É£ Directores con m√°s t√≠tulos en Netflix
print("\n4Ô∏è‚É£ ¬øQu√© directores tienen m√°s t√≠tulos en Netflix?")
df.groupBy("director", "type") \
  .count() \
  .orderBy(col("count").desc()) \
  .na.drop(subset=["director"]) \
  .show(20)

# 5Ô∏è‚É£ Duraci√≥n promedio de las pel√≠culas seg√∫n g√©nero o rating
print("\n5Ô∏è‚É£ ¬øCu√°l es la duraci√≥n promedio de las pel√≠culas seg√∫n su g√©nero o rating?")
df_duration = df.filter(df.type == "Movie").withColumn("duration_num", split(col("duration"), " ").getItem(0).cast("int"))
df_duration.groupBy("rating").avg("duration_num").orderBy("avg(duration_num)", ascending=False).show(20)

# 6Ô∏è‚É£ Pa√≠ses con m√°s contenido adulto (TV-MA) y familiar (TV-Y, TV-G)
print("\n6Ô∏è‚É£ ¬øQu√© pa√≠ses concentran m√°s contenido adulto y familiar?")
adult = df.filter(col("rating") == "TV-MA").groupBy("country").count().orderBy(col("count").desc())
family = df.filter(col("rating").isin("TV-Y", "TV-G")).groupBy("country").count().orderBy(col("count").desc())
print("Contenido adulto (TV-MA):")
adult.show(10)
print("Contenido familiar (TV-Y, TV-G):")
family.show(10)

# 7Ô∏è‚É£ A√±os con m√°s estrenos y g√©neros dominantes
print("\n7Ô∏è‚É£ ¬øEn qu√© a√±os se estrenaron m√°s t√≠tulos y qu√© g√©neros dominaban?")
df_genres.groupBy("release_year", "genre").count().orderBy(col("count").desc()).show(20)

# 8Ô∏è‚É£ Relaci√≥n entre n√∫mero de actores listados y tipo/g√©nero
print("\n8Ô∏è‚É£ ¬øExiste relaci√≥n entre el n√∫mero de actores listados y el tipo de contenido?")
df_cast = df.withColumn("num_cast", size(split(col("cast"), ", ")))
df_cast.groupBy("type").avg("num_cast").orderBy("type").show()

# 9Ô∏è‚É£ Proporci√≥n de coproducciones (t√≠tulos con varios pa√≠ses)
print("\n9Ô∏è‚É£ ¬øCu√°l es la proporci√≥n de coproducciones por g√©nero?")
df_multi_country = df.withColumn("num_countries", size(split(col("country"), ", ")))
df_multi_country.groupBy("type").agg(
    (count(when(col("num_countries") > 1, True)) / count("*") * 100).alias("porcentaje_coproducciones")
).show()

# 10Ô∏è‚É£ Proporci√≥n de t√≠tulos recientes (√∫ltimos 3 a√±os del dataset)


print("\nüîü ¬øQu√© proporci√≥n del cat√°logo corresponde a t√≠tulos recientes?")
print('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')
print(df.columns)
print('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa')

# Convertir release_year a int y eliminar filas no v√°lidas
df_clean = df.withColumn("release_year_int", col("release_year").cast("int")).dropna(subset=["release_year_int"])
# Obtener a√±o m√°ximo correctamente
max_year = df_clean.agg(spark_max("release_year_int")).collect()[0][0]
# Filtrar √∫ltimos 3 a√±os
recent = df_clean.filter(col("release_year_int") >= (max_year - 3))
total = df_clean.count()
recent_count = recent.count()

print(f"T√≠tulos recientes (√∫ltimos 3 a√±os): {recent_count} de {total} ({recent_count/total*100:.2f}%)")


# ----------------------------------------------------------------------
# Finalizar la sesi√≥n
# ----------------------------------------------------------------------
spark.stop()
print("\n‚úÖ An√°lisis completado correctamente.")
